- in the logs from execution from server side, I can see that the assistant content is only visible in the end and during the exchange of messages is always empty - this needs analysis
- sometimes during the agent execution, the mouse gets in "hidden" state, for example after a mouse move the mouse is indeed moved correctly and seems like model sees the mouse, but I dont see the mouse pointer, I have even checked the dump images and its sometimes not visible but model sees it - either its a case of the image creation before cursor is drawn or this is the Windows API tricky legacy issue which requires "jiggling" or who knows what this is, its not an issue for this moment to analyze but its one of the crucial to solve, we cannot have hidden cursors (solutions: jiggling, force draw it, use proper order of executed commands in the windows api section, other)
- in the LM Studio GUI there is an experimental function to enable reasoning content to be visible as a separate field in the JSON, which makes not only "content" but also "reasoning_content" field to be available in theory for observation what model is thinking but in reality its a possible way to "inject" something - for now, its a fun fact, but it has huge potential in the future - during experiments with the self-awareness of the model
